# DataStore Pandas å…¼å®¹æ€§æ”¹è¿›å»ºè®®æŠ¥å‘Š

## æ‰§è¡Œæ‘˜è¦

æœ¬æŠ¥å‘ŠåŸºäºå¯¹ GitHub ä¸Š 15 ä¸ªçƒ­é—¨ Jupyter Notebook é¡¹ç›®çš„åˆ†æï¼ˆå…± 331 ä¸ª pandas æ“ä½œç¤ºä¾‹ï¼‰ï¼Œä»¥åŠé€šè¿‡ `import datastore as pd` æ–¹å¼è¿›è¡Œçš„ monkey patch å…¼å®¹æ€§æµ‹è¯•ã€‚

### æµ‹è¯•ç»“æœæ¦‚è§ˆ

- **æ€»æµ‹è¯•æ•°**: 44 ä¸ªæ ¸å¿ƒæ“ä½œ
- **Pandas æˆåŠŸç‡**: 43/44 (97.7%)
- **DataStore æˆåŠŸç‡**: 40/44 (90.9%)
- **ä¸¤è€…éƒ½æˆåŠŸ**: 40/44 (90.9%)
- **ç»“æœåŒ¹é…ç‡**: 18/40 (45.0%)

### æ•°æ®æ¥æº

**åˆ†æçš„ Notebook ä»“åº“**:
- donnemartin/data-science-ipython-notebooks (6 ä¸ªæ–‡ä»¶)
- jvns/pandas-cookbook (7 ä¸ªæ–‡ä»¶)
- KeithGalli/complete-pandas-tutorial (1 ä¸ªæ–‡ä»¶)
- LearnDataSci/articles (1 ä¸ªæ–‡ä»¶)

**æå–çš„æ“ä½œåˆ†å¸ƒ**:
1. æ•°æ®é€‰æ‹© (Data Selection): 207 ä¸ªç¤ºä¾‹
2. DataFrame åˆ›å»º (DataFrame Creation): 26 ä¸ªç¤ºä¾‹
3. æ•°æ®æ¸…æ´— (Data Cleaning): 24 ä¸ªç¤ºä¾‹
4. ç»Ÿè®¡æ“ä½œ (Statistics): 24 ä¸ªç¤ºä¾‹
5. æ•°æ®è½¬æ¢ (Data Transformation): 17 ä¸ªç¤ºä¾‹
6. æ’åº (Sorting): 12 ä¸ªç¤ºä¾‹
7. èšåˆæ“ä½œ (Aggregation): 6 ä¸ªç¤ºä¾‹
8. å­—ç¬¦ä¸²æ“ä½œ (String Operations): 6 ä¸ªç¤ºä¾‹
9. åˆå¹¶æ“ä½œ (Merging): 5 ä¸ªç¤ºä¾‹
10. æ—¶é—´åºåˆ—æ“ä½œ (DateTime Operations): 4 ä¸ªç¤ºä¾‹

---

## ä¼˜å…ˆçº§ 1: å…³é”®å…¼å®¹æ€§é—®é¢˜ (Critical)

### 1.1 å¸ƒå°”ç´¢å¼•ä¸æ”¯æŒ

**é—®é¢˜**: `df[df['age'] > 30]` æŠ›å‡º `TypeError: DataStore indices must be slices, strings, or lists, not BinaryCondition`

**å½±å“**: è¿™æ˜¯ pandas ä¸­æœ€å¸¸ç”¨çš„è¿‡æ»¤æ–¹å¼ä¹‹ä¸€ï¼Œåœ¨åˆ†æçš„ 207 ä¸ªæ•°æ®é€‰æ‹©ç¤ºä¾‹ä¸­å æ¯”å¾ˆé«˜ã€‚

**å»ºè®®ä¿®å¤**:
```python
# éœ€è¦æ”¯æŒçš„æ¨¡å¼
df[df['age'] > 30]
df[(df['age'] > 30) & (df['salary'] > 50000)]
df[df['name'].str.contains('Alice')]
```

**å®ç°æ–¹æ¡ˆ**:
- åœ¨ `__getitem__` æ–¹æ³•ä¸­æ£€æµ‹ `BinaryCondition` ç±»å‹
- å°†æ¡ä»¶è½¬æ¢ä¸ºç­‰æ•ˆçš„ `.filter()` æ“ä½œ
- ç¡®ä¿è¿”å›ç»“æœä¸ pandas ä¸€è‡´ï¼ˆåŒ…æ‹¬ç´¢å¼•ï¼‰

### 1.2 GroupBy.size() æ–¹æ³•ä¸å¯ç”¨

**é—®é¢˜**: `df.groupby('department').size()` æŠ›å‡º `TypeError: 'ColumnExpr' object is not callable`

**å½±å“**: size() æ˜¯åˆ†ç»„åè®¡æ•°çš„æ ‡å‡†æ–¹æ³•ï¼Œåœ¨å®é™…æ•°æ®åˆ†æä¸­æä¸ºå¸¸ç”¨ã€‚

**å»ºè®®ä¿®å¤**:
```python
# éœ€è¦æ”¯æŒ
df.groupby('col').size()  # è¿”å› Seriesï¼ŒåŒ…å«æ¯ç»„çš„è¡Œæ•°
```

**å®ç°æ–¹æ¡ˆ**:
- åœ¨ `LazyGroupBy` ç±»ä¸­å®ç° `size()` æ–¹æ³•
- è¿”å›æ¯ç»„çš„è®¡æ•°ï¼Œä¸æ’é™¤ NaN å€¼
- æ³¨æ„ä¸ `count()` çš„åŒºåˆ«ï¼ˆcount æ’é™¤ NaNï¼‰

### 1.3 String æ“ä½œå‚æ•°ä¸å…¼å®¹

**é—®é¢˜**: `df['name'].str.contains('a', na=False)` æŠ›å‡º `TypeError: _build_contains() got an unexpected keyword argument 'na'`

**å½±å“**: pandas çš„ str.contains() é»˜è®¤å¯¹ NaN è¿”å› NaNï¼Œéœ€è¦ `na=False` å‚æ•°æ§åˆ¶ã€‚

**å»ºè®®ä¿®å¤**:
```python
# StringAccessor._build_contains() éœ€è¦æ”¯æŒä»¥ä¸‹å‚æ•°
.str.contains(pattern, case=True, flags=0, na=None, regex=True)
```

**å®ç°æ–¹æ¡ˆ**:
- æ›´æ–° `StringAccessor` ä¸­çš„ `contains()` æ–¹æ³•ç­¾å
- æ­£ç¡®å¤„ç† `na` å‚æ•°ï¼ˆå¡«å…… NaN å€¼çš„è¿”å›ç»“æœï¼‰

---

## ä¼˜å…ˆçº§ 2: ç»“æœå·®å¼‚é—®é¢˜ (High Priority)

ä»¥ä¸‹æ“ä½œè™½ç„¶èƒ½æ‰§è¡ŒæˆåŠŸï¼Œä½†ç»“æœä¸ pandas ä¸ä¸€è‡´ï¼š

### 2.1 æ’åºæ“ä½œç»“æœä¸ä¸€è‡´

**é—®é¢˜**: æ‰€æœ‰æ’åºæ“ä½œï¼ˆsort_values, sort_indexï¼‰ç»“æœéƒ½ä¸ pandas ä¸åŒ

**æµ‹è¯•å¤±è´¥**:
- `df.sort_values('age')` âœ—
- `df.sort_values(['department', 'age'])` âœ—
- `df.sort_values('salary', ascending=False)` âœ—
- `df.sort_index()` âœ—

**å¯èƒ½åŸå› **:
1. ç´¢å¼•é‡ç½®ç­–ç•¥ä¸åŒ
2. NaN å€¼æ’åºä½ç½®ä¸åŒ
3. ç¨³å®šæ’åº (stable sort) å®ç°å·®å¼‚
4. å¤šåˆ—æ’åºä¼˜å…ˆçº§å¤„ç†ä¸åŒ

**å»ºè®®ä¿®å¤**:
```python
# éœ€è¦å®Œå…¨åŒ¹é… pandas çš„è¡Œä¸º
- NaN å€¼é»˜è®¤æ’åœ¨æœ€åï¼ˆascending=Trueï¼‰æˆ–æœ€å‰ï¼ˆascending=Falseï¼‰
- ä¿æŒåŸå§‹ç´¢å¼•ï¼Œé™¤é ignore_index=True
- å¤šåˆ—æ’åºæŒ‰åˆ—é¡ºåºä¼˜å…ˆçº§
- ä½¿ç”¨ç¨³å®šæ’åºç®—æ³•
```

### 2.2 æ•°æ®æ¸…æ´—æ“ä½œç»“æœä¸ä¸€è‡´

**é—®é¢˜**: dropna, fillna, drop_duplicates, replace, drop ç­‰æ‰€æœ‰æ¸…æ´—æ“ä½œç»“æœéƒ½ä¸åŒ¹é…

**æµ‹è¯•å¤±è´¥**:
- `df.dropna()` âœ—
- `df.fillna(0)` âœ—
- `df.drop_duplicates()` âœ—
- `df.replace('HR', 'Human Resources')` âœ—
- `df.drop('salary', axis=1)` âœ—

**å¯èƒ½åŸå› **:
1. è¿”å›ç±»å‹ä¸åŒï¼ˆå¯èƒ½è¿”å› LazyOps è€Œé DataFrameï¼‰
2. ç´¢å¼•å¤„ç†ä¸åŒ
3. inplace å‚æ•°å¤„ç†ä¸åŒ
4. åˆ—é¡ºåºå¯èƒ½æ”¹å˜

**å»ºè®®ä¿®å¤**:
- ç¡®ä¿è¿”å› pandas å…¼å®¹çš„ DataFrame å¯¹è±¡
- ä¿æŒåŸå§‹åˆ—é¡ºåº
- æ­£ç¡®å¤„ç†ç´¢å¼•
- å®Œæ•´å®ç° inplace å‚æ•°

### 2.3 å­—ç¬¦ä¸²æ“ä½œç»“æœä¸ä¸€è‡´

**é—®é¢˜**: str.upper(), str.lower(), str.len(), str.replace() ç­‰æ‰€æœ‰å­—ç¬¦ä¸²æ“ä½œç»“æœéƒ½ä¸åŒ¹é…

**æµ‹è¯•å¤±è´¥**:
- `df['name'].str.upper()` âœ—
- `df['city'].str.lower()` âœ—
- `df['name'].str.len()` âœ—
- `df['city'].str.replace('York', 'Amsterdam')` âœ—

**å¯èƒ½åŸå› **:
1. è¿”å›ç±»å‹ä¸åŒï¼ˆå¯èƒ½æ˜¯ ColumnExpr è€Œé Seriesï¼‰
2. NaN å€¼å¤„ç†ä¸åŒ
3. ç´¢å¼•æœªæ­£ç¡®ä¼ é€’

**å»ºè®®ä¿®å¤**:
```python
# ç¡®ä¿å­—ç¬¦ä¸²æ“ä½œè¿”å›æ­£ç¡®çš„ Series
result = df['name'].str.upper()
assert isinstance(result, pd.Series)  # æˆ– datastore çš„ Series ç±»
assert result.index.equals(df.index)  # ç´¢å¼•å¿…é¡»åŒ¹é…
assert pd.isna(result[pd.isna(df['name'])]).all()  # NaN ä¼ é€’
```

### 2.4 DateTime æ“ä½œç»“æœä¸ä¸€è‡´

**é—®é¢˜**: æ‰€æœ‰æ—¥æœŸæ—¶é—´æ“ä½œç»“æœéƒ½ä¸åŒ¹é…

**æµ‹è¯•å¤±è´¥**:
- `pd.to_datetime(df['hire_date'])` âœ—
- `df['hire_date'].dt.year` âœ—
- `df['hire_date'].dt.month` âœ—
- `df['hire_date'].dt.strftime('%Y-%m')` âœ—

**é”™è¯¯ä¿¡æ¯** (ä»æ—¥å¿—):
```
E [chDB] Expression evaluation failed: Code: 43. DB::Exception: Illegal type String of argument of function toYear. Should be Date, Date32, DateTime or DateTime64
```

**æ ¹æœ¬åŸå› **:
- to_datetime() å¯èƒ½æ²¡æœ‰çœŸæ­£è½¬æ¢ç±»å‹ï¼Œä»ç„¶æ˜¯å­—ç¬¦ä¸²
- dt accessor æœŸæœ› DateTime ç±»å‹ä½†æ¥æ”¶åˆ° String

**å»ºè®®ä¿®å¤**:
```python
# to_datetime å¿…é¡»çœŸæ­£è½¬æ¢ç±»å‹
df['date'] = pd.to_datetime(df['date_str'])
# å†…éƒ¨åº”è¯¥å°† ClickHouse åˆ—ç±»å‹ä» String è½¬æ¢ä¸º DateTime64
# dt accessor åº”è¯¥æ£€æŸ¥ç±»å‹å¹¶åœ¨éœ€è¦æ—¶è‡ªåŠ¨è½¬æ¢
```

### 2.5 å…¶ä»–ç»“æœä¸ä¸€è‡´çš„æ“ä½œ

- `df[:3]` - åˆ‡ç‰‡ç»“æœä¸åŒ
- `df.rename(columns={...})` - é‡å‘½åç»“æœä¸åŒ
- `df['new_col'] = expr` - æ·»åŠ æ–°åˆ—å DataFrame ä¸åŒ
- `df.groupby().agg({...})` - å¤šåˆ—èšåˆç»“æœæ ¼å¼ä¸åŒ
- `df.describe()` - ç»Ÿè®¡æ‘˜è¦æ ¼å¼ä¸åŒ

---

## ä¼˜å…ˆçº§ 3: åŠŸèƒ½å¢å¼ºå»ºè®® (Medium Priority)

### 3.1 å®Œå–„ DataFrame æ„é€ å™¨

**å½“å‰çŠ¶æ€**: åŸºæœ¬çš„ DataFrame åˆ›å»ºå·²æ”¯æŒ

**éœ€è¦å¢å¼º**:
```python
# ä» notebook åˆ†æä¸­æå–çš„å¸¸è§æ¨¡å¼
pd.DataFrame(data, columns=['a', 'b'], index=['x', 'y'])  # âœ“ å·²æ”¯æŒ
pd.DataFrame([{'a': 1, 'b': 2}, {'b': 3, 'c': 4}])  # éœ€è¦æµ‹è¯•
pd.DataFrame(np.random.rand(3, 2), columns=['A', 'B'])  # éœ€è¦æµ‹è¯•
pd.DataFrame.from_dict({...}, orient='index')  # éœ€è¦æ”¯æŒ
pd.DataFrame.from_records([...])  # éœ€è¦æ”¯æŒ
```

### 3.2 å®Œå–„ read_* å‡½æ•°

**ä»åˆ†æä¸­å‘ç°çš„å¸¸ç”¨æ¨¡å¼**:
```python
# éœ€è¦ç¡®ä¿æ”¯æŒæ‰€æœ‰è¿™äº›å‚æ•°ç»„åˆ
pd.read_csv('file.csv', parse_dates=True, index_col='Date')
pd.read_csv('file.csv', sep=';', encoding='latin1')
pd.read_csv('file.csv', dtype={'col': str})
pd.read_csv('file.csv', na_values=['NA', 'null'])
pd.read_csv('file.csv', parse_dates=['date_col'], dayfirst=True)
```

### 3.3 æ”¯æŒ apply/map çš„ lambda å‡½æ•°

**é—®é¢˜**: å½“å‰ apply/map å¯èƒ½ä¸æ”¯æŒå¤æ‚çš„ lambda

**éœ€è¦æ”¯æŒ**:
```python
df['age'].apply(lambda x: x * 2 if pd.notna(x) else x)
df['category'].map({'A': 1, 'B': 2, 'C': 3})
df.apply(lambda row: row['a'] + row['b'], axis=1)
df.applymap(lambda x: str(x).upper())  # DataFrame level
```

**å®ç°æŒ‘æˆ˜**:
- ClickHouse ä¸æ”¯æŒè‡ªå®šä¹‰ Python å‡½æ•°
- éœ€è¦å›é€€åˆ° pandas æ‰§è¡Œæˆ–å°è¯•è½¬æ¢ä¸º SQL

**å»ºè®®æ–¹æ¡ˆ**:
1. ç®€å•è¡¨è¾¾å¼å°è¯•è½¬æ¢ä¸º SQLï¼ˆå¦‚ `x * 2`ï¼‰
2. å¤æ‚ lambda å›é€€åˆ° pandas æ‰§è¡Œ
3. æä¾›é…ç½®é€‰é¡¹è®©ç”¨æˆ·é€‰æ‹©æ‰§è¡Œå¼•æ“

### 3.4 å®Œå–„ç»Ÿè®¡æ–¹æ³•

**å½“å‰çŠ¶æ€**: mean, sum, median, std å·²åŒ¹é…

**éœ€è¦å¢å¼º**:
```python
# ç¡®ä¿ä»¥ä¸‹æ–¹æ³•å®Œå…¨å…¼å®¹
df.describe()  # ç»“æœæ ¼å¼éœ€è¦åŒ¹é…
df.quantile([0.25, 0.75])
df.corr(method='pearson')  # æ”¯æŒä¸åŒæ–¹æ³•
df.cov()
df.value_counts(normalize=True, dropna=False)
```

### 3.5 å®Œå–„ GroupBy åŠŸèƒ½

**éœ€è¦æ”¯æŒ**:
```python
# å¤šç§èšåˆæ–¹å¼
df.groupby('col').agg(['mean', 'sum', 'count'])
df.groupby('col').agg({'col1': 'mean', 'col2': ['min', 'max']})
df.groupby('col').transform(lambda x: x - x.mean())
df.groupby(['col1', 'col2']).size()  # å¤šåˆ—åˆ†ç»„
df.groupby('col').filter(lambda x: len(x) > 2)

# ç¡®ä¿è¿”å›æ ¼å¼ä¸ pandas ä¸€è‡´
- å•åˆ—å•èšåˆ -> Series
- å¤šåˆ—æˆ–å¤šèšåˆ -> DataFrame
- æ­£ç¡®çš„åˆ—åï¼ˆMultiIndex æˆ–æ‰å¹³ï¼‰
```

---

## ä¼˜å…ˆçº§ 4: æ–°åŠŸèƒ½æ”¯æŒ (Lower Priority)

### 4.1 æ”¯æŒæ›´å¤š IO æ ¼å¼

ä» notebook åˆ†æä¸­å‘ç°çš„ä½¿ç”¨é¢‘ç‡ï¼š
```python
pd.read_csv()     # 26 æ¬¡ - âœ“ å·²æ”¯æŒ
pd.read_excel()   # éœ€è¦æµ‹è¯•
pd.read_json()    # éœ€è¦æµ‹è¯•
pd.read_sql()     # éœ€è¦æµ‹è¯•
pd.read_parquet() # éœ€è¦æµ‹è¯•
pd.read_html()    # ä½ä¼˜å…ˆçº§
```

### 4.2 æ”¯æŒæ—¶é—´åºåˆ—ç‰¹æ€§

```python
# ä» notebook å‘ç°çš„å¸¸ç”¨æ“ä½œ
pd.date_range('2020-01-01', '2020-12-31', freq='D')
df.resample('M').mean()  # æ—¶é—´é‡é‡‡æ ·
df.rolling(window=7).mean()  # æ»šåŠ¨çª—å£
df.shift(1)  # æ—¶é—´ä½ç§»
```

### 4.3 æ”¯æŒæ•°æ®é‡å¡‘

```python
# ä» notebook å‘ç°çš„å¸¸ç”¨æ“ä½œ
pd.pivot_table(df, values='value', index='row', columns='col')
pd.melt(df, id_vars=['id'], value_vars=['a', 'b'])
df.stack() / df.unstack()
df.transpose()
```

---

## å®ç°è·¯çº¿å›¾å»ºè®®

### Phase 1: å…³é”®ä¿®å¤ (1-2 å‘¨)
1. âœ… å¸ƒå°”ç´¢å¼•æ”¯æŒ
2. âœ… GroupBy.size() å®ç°
3. âœ… å­—ç¬¦ä¸²æ“ä½œå‚æ•°å…¼å®¹
4. âœ… DateTime ç±»å‹è½¬æ¢ä¿®å¤

### Phase 2: ç»“æœä¸€è‡´æ€§ (2-3 å‘¨)
1. ğŸ”§ ä¿®å¤æ‰€æœ‰æ’åºæ“ä½œ
2. ğŸ”§ ä¿®å¤æ•°æ®æ¸…æ´—æ“ä½œ
3. ğŸ”§ ä¿®å¤å­—ç¬¦ä¸²æ“ä½œè¿”å›ç±»å‹
4. ğŸ”§ ç»Ÿä¸€ DataFrame/Series è¾“å‡ºæ ¼å¼

### Phase 3: åŠŸèƒ½å¢å¼º (3-4 å‘¨)
1. ğŸ“ˆ å®Œå–„ apply/map/lambda æ”¯æŒ
2. ğŸ“ˆ å¢å¼º GroupBy èšåˆåŠŸèƒ½
3. ğŸ“ˆ å®Œå–„ç»Ÿè®¡æ–¹æ³•
4. ğŸ“ˆ å¢å¼º IO åŠŸèƒ½

### Phase 4: é«˜çº§ç‰¹æ€§ (æŒç»­)
1. ğŸ¯ æ—¶é—´åºåˆ—å®Œæ•´æ”¯æŒ
2. ğŸ¯ æ•°æ®é‡å¡‘åŠŸèƒ½
3. ğŸ¯ æ€§èƒ½ä¼˜åŒ–
4. ğŸ¯ å®Œæ•´çš„å•å…ƒæµ‹è¯•è¦†ç›–

---

## æµ‹è¯•ç­–ç•¥å»ºè®®

### 1. åˆ›å»ºå…¼å®¹æ€§æµ‹è¯•å¥—ä»¶

åŸºäºæœ¬æ¬¡åˆ†æçš„ 331 ä¸ªçœŸå®ç¤ºä¾‹ï¼Œåˆ›å»ºè‡ªåŠ¨åŒ–æµ‹è¯•ï¼š

```python
# tests/test_pandas_compatibility.py
class TestPandasCompatibility:
    def test_real_world_examples(self):
        """æµ‹è¯•ä»çœŸå® notebook æå–çš„æ‰€æœ‰æ“ä½œ"""
        with open('pandas_operations_analysis.json') as f:
            operations = json.load(f)

        for category, ops in operations['detailed_operations'].items():
            for example in ops['examples']:
                # æ¯”è¾ƒ pandas å’Œ datastore ç»“æœ
                assert_results_match(example['code'])
```

### 2. å»ºç«‹æŒç»­é›†æˆ

```yaml
# .github/workflows/pandas-compat.yml
- name: Pandas Compatibility Test
  run: |
    python pandas_compatibility_test.py
    # å¦‚æœå…¼å®¹ç‡ä½äº 95%ï¼Œåˆ™å¤±è´¥
```

### 3. åˆ›å»ºå…¼å®¹æ€§çŸ©é˜µæ–‡æ¡£

| æ“ä½œç±»å‹ | æ”¯æŒåº¦ | æ³¨æ„äº‹é¡¹ |
|---------|-------|---------|
| DataFrame åˆ›å»º | âœ… 100% | - |
| æ•°æ®é€‰æ‹© | âš ï¸ 83% | ä¸æ”¯æŒå¸ƒå°”ç´¢å¼• |
| ç»Ÿè®¡æ“ä½œ | âœ… 95% | describe() æ ¼å¼ç•¥æœ‰å·®å¼‚ |
| ... | ... | ... |

---

## ç‰¹å®šé—®é¢˜æ·±åº¦åˆ†æ

### é—®é¢˜ 1: ä¸ºä»€ä¹ˆç»“æœ"éƒ½ä¸åŒ¹é…"ï¼Ÿ

æµ‹è¯•æ˜¾ç¤ºå¾ˆå¤šæ“ä½œè™½ç„¶æˆåŠŸæ‰§è¡Œï¼Œä½†ç»“æœä¸åŒ¹é…ã€‚ç»åˆ†æï¼Œä¸»è¦åŸå› ï¼š

#### 1.1 è¿”å›ç±»å‹é—®é¢˜

```python
# Pandas è¿”å›
type(df.dropna())  # pandas.DataFrame

# DataStore å¯èƒ½è¿”å›
type(df.dropna())  # datastore.lazy_result.LazyOps
str(df.dropna())   # <LazyOps: SELECT ...>
```

**è§£å†³æ–¹æ¡ˆ**: ç¡®ä¿æ‰€æœ‰æ–¹æ³•åœ¨ `__str__()` å’Œ `__repr__()` æ—¶è‡ªåŠ¨æ‰§è¡Œå¹¶è¿”å›ç±»ä¼¼ pandas çš„è¡¨ç¤ºã€‚

#### 1.2 ç´¢å¼•å¤„ç†é—®é¢˜

```python
# Pandas ä¿æŒåŸç´¢å¼•
df_filtered = df[df['age'] > 30]
df_filtered.index  # [1, 2, 4] (åŸå§‹ç´¢å¼•)

# DataStore å¯èƒ½é‡ç½®ç´¢å¼•
df_filtered.index  # [0, 1, 2] (æ–°ç´¢å¼•)
```

**è§£å†³æ–¹æ¡ˆ**:
- é»˜è®¤ä¿æŒåŸç´¢å¼•
- æä¾› `reset_index()` æ˜¾å¼é‡ç½®
- åœ¨ SQL ä¸­ä½¿ç”¨ ROW_NUMBER æˆ–ç±»ä¼¼æœºåˆ¶è¿½è¸ªåŸç´¢å¼•

#### 1.3 åˆ—é¡ºåºé—®é¢˜

```python
# Pandas ä¿æŒåˆ—é¡ºåº
df.drop('col', axis=1)  # å…¶ä»–åˆ—é¡ºåºä¸å˜

# DataStore å¯èƒ½é‡æ’
df.drop('col', axis=1)  # SELECT * å¯èƒ½æ”¹å˜é¡ºåº
```

**è§£å†³æ–¹æ¡ˆ**: åœ¨ SQL ç”Ÿæˆæ—¶æ˜¾å¼æŒ‡å®šåˆ—é¡ºåºã€‚

### é—®é¢˜ 2: å¦‚ä½•æ”¯æŒå¤æ‚çš„ Lambda å‡½æ•°ï¼Ÿ

è¿™æ˜¯ä¸€ä¸ªæŠ€æœ¯æŒ‘æˆ˜ï¼Œå› ä¸º ClickHouse ä¸èƒ½ç›´æ¥æ‰§è¡Œ Python ä»£ç ã€‚

#### æ–¹æ¡ˆ A: SQL è½¬æ¢ï¼ˆæœ‰é™æ”¯æŒï¼‰

```python
# å¯ä»¥è½¬æ¢çš„ç®€å•è¡¨è¾¾å¼
df['age'].apply(lambda x: x * 2)
# -> SELECT age * 2 FROM table

df['age'].apply(lambda x: x if x > 18 else 0)
# -> SELECT if(age > 18, age, 0) FROM table
```

ä½¿ç”¨ AST åˆ†æ lambda è¡¨è¾¾å¼ï¼Œè½¬æ¢ä¸ºç­‰æ•ˆ SQLã€‚

#### æ–¹æ¡ˆ B: æ··åˆæ‰§è¡Œ

```python
# é…ç½®é¡¹
import datastore as pd
pd.config.set_option('compute.engine', 'auto')  # é»˜è®¤
pd.config.set_option('compute.engine', 'chdb')  # å¼ºåˆ¶ chdb
pd.config.set_option('compute.engine', 'pandas')  # å¼ºåˆ¶ pandas

# è‡ªåŠ¨é€‰æ‹©ï¼šç®€å•è¡¨è¾¾å¼ç”¨ chdbï¼Œå¤æ‚çš„ç”¨ pandas
df['result'] = df['col'].apply(complex_lambda)  # è‡ªåŠ¨é™çº§åˆ° pandas
```

#### æ–¹æ¡ˆ C: UDF æ”¯æŒï¼ˆé•¿æœŸï¼‰

æ¢ç´¢ ClickHouse çš„ UDF åŠŸèƒ½ï¼Œè™½ç„¶å¯èƒ½æœ‰æ€§èƒ½æŸå¤±ã€‚

---

## æ€§èƒ½è€ƒè™‘

### ä½•æ—¶ DataStore æ›´å¿«ï¼Ÿ

```python
# å¤§æ•°æ®é›† + ç®€å•æ“ä½œ = DataStore èƒœ
df = pd.read_csv('huge_file.csv')  # 1GB+
result = df.groupby('category').mean()  # ClickHouse ä¼˜åŒ–çš„èšåˆ

# å°æ•°æ®é›† + å¤æ‚æ“ä½œ = Pandas å¯èƒ½æ›´å¿«
df = pd.read_csv('small_file.csv')  # 10KB
result = df.apply(complex_function)  # Python UDF å¼€é”€å¤§
```

### å»ºè®®

- æä¾›æ€§èƒ½åŸºå‡†æµ‹è¯•è„šæœ¬
- åœ¨æ–‡æ¡£ä¸­è¯´æ˜æœ€ä½³ä½¿ç”¨åœºæ™¯
- æä¾› `explain()` æ–¹æ³•æ˜¾ç¤ºæ‰§è¡Œè®¡åˆ’

---

## æ–‡æ¡£æ”¹è¿›å»ºè®®

### 1. åˆ›å»ºè¿ç§»æŒ‡å—

```markdown
# ä» Pandas è¿ç§»åˆ° DataStore

## å®Œå…¨å…¼å®¹çš„æ“ä½œ
- âœ… read_csv, read_parquet
- âœ… df.select, df.filter
- âœ… df.groupby().mean/sum/count
...

## éœ€è¦ä¿®æ”¹çš„æ“ä½œ
- âš ï¸ df[df['col'] > value] -> df.filter(df['col'] > value)
- âš ï¸ df.groupby().size() -> df.groupby().count()
...

## ä¸æ”¯æŒçš„æ“ä½œ
- âŒ df.apply(lambda x: custom_func(x))
- âŒ df.pivot_table(...) [å¼€å‘ä¸­]
...
```

### 2. åˆ›å»ºæ€§èƒ½å¯¹æ¯”æ–‡æ¡£

å±•ç¤º DataStore åœ¨å“ªäº›åœºæ™¯ä¸‹ä¼˜äº Pandasï¼š
- å¤§æ–‡ä»¶è¯»å–
- èšåˆæ“ä½œ
- å¤šè¡¨ JOIN

### 3. åˆ›å»ºæ•…éšœæ’é™¤æŒ‡å—

å¸¸è§é”™è¯¯å’Œè§£å†³æ–¹æ¡ˆï¼š
```markdown
## é”™è¯¯: "BinaryCondition not supported"
**åŸå› **: ä½¿ç”¨äº†å¸ƒå°”ç´¢å¼•
**è§£å†³**: æ”¹ç”¨ .filter() æ–¹æ³•
...
```

---

## é™„å½•

### A. å®Œæ•´æµ‹è¯•ç»“æœ

è¯¦è§æ–‡ä»¶:
- `pandas_compatibility_report.txt` - å¯è¯»æŠ¥å‘Š
- `pandas_compatibility_results.json` - è¯¦ç»† JSON æ•°æ®

### B. åˆ†æçš„ Notebook åˆ—è¡¨

è¯¦è§æ–‡ä»¶:
- `pandas_operations_analysis.json` - 331 ä¸ªæ“ä½œç¤ºä¾‹
- `downloaded_notebooks/` - 15 ä¸ªåŸå§‹ notebook æ–‡ä»¶

### C. æµ‹è¯•è„šæœ¬

- `pandas_compatibility_test.py` - è‡ªåŠ¨åŒ–æµ‹è¯•è„šæœ¬

å¯ä»¥è¿è¡Œï¼š
```bash
python pandas_compatibility_test.py
```

ç”Ÿæˆæœ€æ–°çš„å…¼å®¹æ€§æŠ¥å‘Šã€‚

---

## æ€»ç»“

DataStore å·²ç»å®ç°äº†ç›¸å½“ç¨‹åº¦çš„ pandas å…¼å®¹æ€§ï¼ˆ90.9% æ“ä½œæˆåŠŸç‡ï¼‰ï¼Œä½†åœ¨ä»¥ä¸‹æ–¹é¢éœ€è¦æ”¹è¿›ï¼š

**ç«‹å³éœ€è¦ä¿®å¤**:
1. å¸ƒå°”ç´¢å¼•æ”¯æŒ
2. GroupBy.size() æ–¹æ³•
3. å­—ç¬¦ä¸²æ“ä½œå‚æ•°

**é‡è¦æ€§èƒ½æ”¹è¿›**:
1. æ‰€æœ‰æ’åºæ“ä½œçš„ç»“æœä¸€è‡´æ€§
2. æ•°æ®æ¸…æ´—æ“ä½œçš„è¿”å›ç±»å‹
3. DateTime ç±»å‹è½¬æ¢

**é•¿æœŸå¢å¼º**:
1. å¤æ‚ lambda æ”¯æŒ
2. æ—¶é—´åºåˆ—åŠŸèƒ½
3. æ•°æ®é‡å¡‘æ“ä½œ

é€šè¿‡ç³»ç»Ÿæ€§åœ°è§£å†³è¿™äº›é—®é¢˜ï¼ŒDataStore å¯ä»¥æˆä¸ºçœŸæ­£çš„"å¯ä»¥ç”¨ `import datastore as pd` æ›¿æ¢ pandas"çš„åº“ï¼ŒåŒæ—¶ä¿æŒå…¶åœ¨å¤§æ•°æ®å¤„ç†ä¸Šçš„æ€§èƒ½ä¼˜åŠ¿ã€‚
