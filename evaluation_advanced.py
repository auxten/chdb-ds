#!/usr/bin/env python3
"""
DataStore API é«˜çº§è¯„æµ‹
======================
é’ˆå¯¹é«˜çº§åŠŸèƒ½ã€è¾¹ç•Œæƒ…å†µå’Œ README ç‰¹åˆ«æåˆ°çš„åŠŸèƒ½è¿›è¡Œæ·±å…¥æµ‹è¯•
"""

import sys
import warnings
warnings.filterwarnings('ignore')

sys.path.insert(0, '/workspace')

from datastore import DataStore, Field, Sum, Count, Avg, Max, Min
from datastore import Upper, Lower, Concat
from datetime import datetime

print("=" * 80)
print("ğŸ”¬ DataStore é«˜çº§åŠŸèƒ½è¯„æµ‹")
print(f"   æ—¥æœŸ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
print("=" * 80)


# ============================================================================
# æµ‹è¯• 1: èšåˆå‡½æ•° (README ä¸­æåˆ°çš„)
# ============================================================================
print("\n\nğŸ“Š æµ‹è¯• 1: èšåˆå‡½æ•°")
print("-" * 60)

try:
    ds = DataStore.from_file("/workspace/tests/dataset/orders.csv")
    ds.connect()
    
    # æµ‹è¯• Sum èšåˆ
    total = ds.select(Sum(Field("amount"), alias="total_amount")).to_df()
    print(f"  âœ… Sum èšåˆ: æ€»é‡‘é¢ = {total['total_amount'].iloc[0]:.2f}")
    
    # æµ‹è¯• Count
    count_result = ds.select(Count("*", alias="order_count")).to_df()
    print(f"  âœ… Count èšåˆ: è®¢å•æ•° = {count_result['order_count'].iloc[0]}")
    
    # æµ‹è¯• Avg
    avg_result = ds.select(Avg(Field("amount"), alias="avg_amount")).to_df()
    print(f"  âœ… Avg èšåˆ: å¹³å‡é‡‘é¢ = {avg_result['avg_amount'].iloc[0]:.2f}")
    
    # æµ‹è¯• Max/Min
    max_result = ds.select(Max(Field("amount"), alias="max_amount")).to_df()
    min_result = ds.select(Min(Field("amount"), alias="min_amount")).to_df()
    print(f"  âœ… Max/Min: æœ€å¤§ = {max_result['max_amount'].iloc[0]:.2f}, æœ€å° = {min_result['min_amount'].iloc[0]:.2f}")
    
except Exception as e:
    print(f"  âŒ èšåˆå‡½æ•°æµ‹è¯•å¤±è´¥: {e}")


# ============================================================================
# æµ‹è¯• 2: GROUP BY å­å¥
# ============================================================================
print("\n\nğŸ“Š æµ‹è¯• 2: GROUP BY å­å¥")
print("-" * 60)

try:
    ds = DataStore.from_file("/workspace/tests/dataset/orders.csv")
    ds.connect()
    
    # GROUP BY user_id
    grouped = (ds
        .select(Field("user_id"), Sum(Field("amount"), alias="total"))
        .groupby("user_id")
        .to_df())
    
    print(f"  âœ… GROUP BY: æŒ‰ user_id åˆ†ç»„ï¼Œå¾—åˆ° {len(grouped)} ä¸ªç”¨æˆ·çš„æ±‡æ€»")
    print(f"     å‰3è¡Œ: {grouped.head(3).to_dict('records')}")
    
except Exception as e:
    print(f"  âŒ GROUP BY æµ‹è¯•å¤±è´¥: {e}")


# ============================================================================
# æµ‹è¯• 3: å­—ç¬¦ä¸²å‡½æ•°
# ============================================================================
print("\n\nğŸ“Š æµ‹è¯• 3: å­—ç¬¦ä¸²å‡½æ•°")
print("-" * 60)

try:
    ds = DataStore.from_file("/workspace/tests/dataset/users.csv")
    ds.connect()
    
    # Upper å‡½æ•°
    result = ds.select(Field("name"), Upper(Field("name"), alias="name_upper")).limit(3).to_df()
    print(f"  âœ… Upper å‡½æ•°: {result['name'].iloc[0]} â†’ {result['name_upper'].iloc[0]}")
    
    # Lower å‡½æ•°
    result = ds.select(Field("name"), Lower(Field("name"), alias="name_lower")).limit(3).to_df()
    print(f"  âœ… Lower å‡½æ•°: {result['name'].iloc[0]} â†’ {result['name_lower'].iloc[0]}")
    
except Exception as e:
    print(f"  âŒ å­—ç¬¦ä¸²å‡½æ•°æµ‹è¯•å¤±è´¥: {e}")


# ============================================================================
# æµ‹è¯• 4: åˆ‡ç‰‡è¯­æ³• (README ä¸­æåˆ°çš„)
# ============================================================================
print("\n\nğŸ“Š æµ‹è¯• 4: åˆ‡ç‰‡è¯­æ³•")
print("-" * 60)

try:
    ds = DataStore.from_file("/workspace/tests/dataset/users.csv")
    ds.connect()
    
    # ds[:5] ç­‰åŒäº LIMIT 5
    result = ds.select("*")[:5].to_df()
    print(f"  âœ… ds[:5] è¿”å› {len(result)} è¡Œ (LIMIT 5)")
    
    # ds[3:] ç­‰åŒäº OFFSET 3
    result2 = ds.select("*")[3:].to_df()
    print(f"  âœ… ds[3:] è¿”å› {len(result2)} è¡Œ (OFFSET 3)")
    
    # ds[2:5] ç­‰åŒäº LIMIT 3 OFFSET 2
    result3 = ds.select("*")[2:5].to_df()
    print(f"  âœ… ds[2:5] è¿”å› {len(result3)} è¡Œ (LIMIT 3 OFFSET 2)")
    
except Exception as e:
    print(f"  âŒ åˆ‡ç‰‡è¯­æ³•æµ‹è¯•å¤±è´¥: {e}")


# ============================================================================
# æµ‹è¯• 5: åˆ—èµ‹å€¼è¯­æ³• (README ä¸­æåˆ°çš„)
# ============================================================================
print("\n\nğŸ“Š æµ‹è¯• 5: åˆ—èµ‹å€¼è¯­æ³• (ds['new_col'] = ...)")
print("-" * 60)

try:
    ds = DataStore.from_file("/workspace/tests/dataset/users.csv")
    ds.connect()
    ds = ds.select("*")
    
    # ä½¿ç”¨åˆ—èµ‹å€¼è¯­æ³•
    ds['age_group'] = 'adult'  # å¸¸é‡èµ‹å€¼
    df = ds.to_df()
    
    has_col = 'age_group' in df.columns
    print(f"  {'âœ…' if has_col else 'âŒ'} å¸¸é‡èµ‹å€¼: 'age_group' åˆ—å·²æ·»åŠ ")
    
    # ä½¿ç”¨è¡¨è¾¾å¼èµ‹å€¼
    ds2 = DataStore.from_file("/workspace/tests/dataset/users.csv")
    ds2.connect()
    ds2 = ds2.select("*")
    ds2['double_age'] = ds2['age'] * 2
    df2 = ds2.to_df()
    
    has_expr_col = 'double_age' in df2.columns
    print(f"  {'âœ…' if has_expr_col else 'âŒ'} è¡¨è¾¾å¼èµ‹å€¼: 'double_age' åˆ—å·²æ·»åŠ ")
    
except Exception as e:
    print(f"  âŒ åˆ—èµ‹å€¼è¯­æ³•æµ‹è¯•å¤±è´¥: {e}")


# ============================================================================
# æµ‹è¯• 6: DISTINCT å»é‡
# ============================================================================
print("\n\nğŸ“Š æµ‹è¯• 6: DISTINCT å»é‡")
print("-" * 60)

try:
    ds = DataStore.from_file("/workspace/tests/dataset/users.csv")
    ds.connect()
    
    # è·å–æ‰€æœ‰ä¸é‡å¤çš„å›½å®¶
    countries = ds.select("country").distinct().to_df()
    print(f"  âœ… DISTINCT: æ‰¾åˆ° {len(countries)} ä¸ªä¸åŒçš„å›½å®¶")
    print(f"     å›½å®¶åˆ—è¡¨: {list(countries['country'])}")
    
    # éªŒè¯ SQL ç”Ÿæˆ
    sql = ds.select("country").distinct().to_sql()
    has_distinct = "DISTINCT" in sql
    print(f"  {'âœ…' if has_distinct else 'âŒ'} SQL åŒ…å« DISTINCT å…³é”®å­—")
    
except Exception as e:
    print(f"  âŒ DISTINCT æµ‹è¯•å¤±è´¥: {e}")


# ============================================================================
# æµ‹è¯• 7: å–åæ¡ä»¶
# ============================================================================
print("\n\nğŸ“Š æµ‹è¯• 7: æ¡ä»¶å–å (~)")
print("-" * 60)

try:
    ds = DataStore.from_file("/workspace/tests/dataset/users.csv")
    ds.connect()
    
    # å–å: ä¸æ˜¯ USA çš„ç”¨æˆ·
    not_usa = ds.select("*").filter(~(ds.country == "USA")).to_df()
    all_not_usa = all(not_usa['country'] != "USA")
    print(f"  {'âœ…' if all_not_usa else 'âŒ'} å–åæ¡ä»¶: æ‰¾åˆ° {len(not_usa)} ä¸ªé USA ç”¨æˆ·")
    
except Exception as e:
    print(f"  âŒ æ¡ä»¶å–åæµ‹è¯•å¤±è´¥: {e}")


# ============================================================================
# æµ‹è¯• 8: å¤šè¡¨ JOIN (README ä¸­é‡ç‚¹æåˆ°)
# ============================================================================
print("\n\nğŸ“Š æµ‹è¯• 8: JOIN æ“ä½œ")
print("-" * 60)

try:
    users = DataStore.from_file("/workspace/tests/dataset/users.csv")
    orders = DataStore.from_file("/workspace/tests/dataset/orders.csv")
    users.connect()
    orders.connect()
    
    # INNER JOIN
    joined = (orders
        .select("*")
        .join(users, left_on="user_id", right_on="user_id", how="inner")
        .to_df())
    
    print(f"  âœ… INNER JOIN: åˆå¹¶å {len(joined)} è¡Œ")
    print(f"     åˆ—: {list(joined.columns)[:6]}...")  # åªæ˜¾ç¤ºå‰6åˆ—
    
except Exception as e:
    print(f"  âŒ JOIN æµ‹è¯•å¤±è´¥: {e}")


# ============================================================================
# æµ‹è¯• 9: Pandas é«˜çº§æ“ä½œ
# ============================================================================
print("\n\nğŸ“Š æµ‹è¯• 9: Pandas é«˜çº§æ“ä½œ")
print("-" * 60)

try:
    ds = DataStore.from_file("/workspace/tests/dataset/users.csv")
    ds.connect()
    
    # pivot_table é£æ ¼æ“ä½œ (é€šè¿‡ groupby + agg)
    df = ds.select("*").to_df()
    pivot = df.groupby('country').agg({'age': ['mean', 'count']}).reset_index()
    print(f"  âœ… åˆ†ç»„èšåˆ: æŒ‰å›½å®¶ç»Ÿè®¡å¹´é¾„å‡å€¼å’Œäººæ•°")
    
    # value_counts
    country_counts = ds.select("*").to_df()['country'].value_counts()
    print(f"  âœ… value_counts: USA ç”¨æˆ· {country_counts.get('USA', 0)} äºº")
    
    # nlargest
    top3 = ds.select("*").nlargest(3, 'age')
    df_top3 = top3.to_df()
    print(f"  âœ… nlargest: å¹´é¾„æœ€å¤§çš„3äºº - {list(df_top3['name'])}")
    
    # nsmallest
    bottom3 = ds.select("*").nsmallest(3, 'age')
    df_bottom3 = bottom3.to_df()
    print(f"  âœ… nsmallest: å¹´é¾„æœ€å°çš„3äºº - {list(df_bottom3['name'])}")
    
except Exception as e:
    print(f"  âŒ Pandas é«˜çº§æ“ä½œæµ‹è¯•å¤±è´¥: {e}")


# ============================================================================
# æµ‹è¯• 10: from_random() ç”Ÿæˆéšæœºæ•°æ®
# ============================================================================
print("\n\nğŸ“Š æµ‹è¯• 10: éšæœºæ•°æ®ç”Ÿæˆ")
print("-" * 60)

try:
    ds = DataStore.from_random(
        structure="id UInt32, name String, value Float64",
        random_seed=42
    )
    ds.connect()
    
    result = ds.select("*").limit(5).to_df()
    print(f"  âœ… from_random: ç”Ÿæˆäº† {len(result)} è¡Œéšæœºæ•°æ®")
    print(f"     åˆ—: {list(result.columns)}")
    print(f"     ç¤ºä¾‹ ID: {list(result['id'])}")
    
except Exception as e:
    print(f"  âŒ éšæœºæ•°æ®ç”Ÿæˆæµ‹è¯•å¤±è´¥: {e}")


# ============================================================================
# æµ‹è¯• 11: explain() è¯¦ç»†è¾“å‡º
# ============================================================================
print("\n\nğŸ“Š æµ‹è¯• 11: explain() æ‰§è¡Œè®¡åˆ’è¯¦æƒ…")
print("-" * 60)

try:
    ds = DataStore.from_file("/workspace/tests/dataset/orders.csv")
    ds.connect()
    
    query = (ds
        .select("user_id", "amount")
        .filter(ds.amount > 100)
        .sort("amount", ascending=False)
        .limit(5))
    
    # æ•è· explain è¾“å‡º
    import io
    import sys
    old_stdout = sys.stdout
    sys.stdout = io.StringIO()
    
    plan = query.explain(verbose=True)
    
    output = sys.stdout.getvalue()
    sys.stdout = old_stdout
    
    # æ£€æŸ¥å…³é”®éƒ¨åˆ†
    has_source = "Data Source" in plan
    has_sql = "SELECT" in plan or "Generated SQL" in plan
    
    print(f"  {'âœ…' if has_source else 'âš ï¸'} æ˜¾ç¤ºæ•°æ®æºä¿¡æ¯")
    print(f"  {'âœ…' if has_sql else 'âš ï¸'} æ˜¾ç¤º SQL æŸ¥è¯¢")
    print("  æ‰§è¡Œè®¡åˆ’é¢„è§ˆ:")
    for line in plan.split('\n')[:10]:
        if line.strip():
            print(f"     {line[:70]}")
    
except Exception as e:
    print(f"  âŒ explain() æµ‹è¯•å¤±è´¥: {e}")


# ============================================================================
# æµ‹è¯• 12: å¤šåˆ—é€‰æ‹©è¯­æ³•
# ============================================================================
print("\n\nğŸ“Š æµ‹è¯• 12: å¤šåˆ—é€‰æ‹©è¯­æ³• ds[['col1', 'col2']]")
print("-" * 60)

try:
    ds = DataStore.from_file("/workspace/tests/dataset/users.csv")
    ds.connect()
    ds = ds.select("*")
    
    # ä½¿ç”¨åˆ—è¡¨é€‰æ‹©å¤šåˆ—
    subset = ds[['name', 'age']].to_df()
    
    correct_cols = list(subset.columns) == ['name', 'age']
    print(f"  {'âœ…' if correct_cols else 'âŒ'} å¤šåˆ—é€‰æ‹©: é€‰æ‹©äº† {list(subset.columns)}")
    
except Exception as e:
    print(f"  âŒ å¤šåˆ—é€‰æ‹©æµ‹è¯•å¤±è´¥: {e}")


# ============================================================================
# æµ‹è¯• 13: ç»Ÿè®¡æ–¹æ³•
# ============================================================================
print("\n\nğŸ“Š æµ‹è¯• 13: ç»Ÿè®¡æ–¹æ³•")
print("-" * 60)

try:
    ds = DataStore.from_file("/workspace/tests/dataset/orders.csv")
    ds.connect()
    ds_full = ds.select("*")
    
    # std æ ‡å‡†å·®
    std = ds_full.std()
    print(f"  âœ… std(): amount æ ‡å‡†å·® = {std.get('amount', 'N/A'):.2f}")
    
    # var æ–¹å·®
    var = ds_full.var()
    print(f"  âœ… var(): amount æ–¹å·® = {var.get('amount', 'N/A'):.2f}")
    
    # quantile åˆ†ä½æ•°
    q = ds_full.quantile(0.5)
    print(f"  âœ… quantile(0.5): amount ä¸­ä½æ•° = {q.get('amount', 'N/A'):.2f}")
    
    # corr ç›¸å…³æ€§
    corr = ds_full.corr()
    print(f"  âœ… corr(): ç›¸å…³çŸ©é˜µç»´åº¦ = {corr.shape}")
    
except Exception as e:
    print(f"  âŒ ç»Ÿè®¡æ–¹æ³•æµ‹è¯•å¤±è´¥: {e}")


# ============================================================================
# æµ‹è¯• 14: æ•°æ®ç±»å‹è½¬æ¢
# ============================================================================
print("\n\nğŸ“Š æµ‹è¯• 14: æ•°æ®ç±»å‹æ“ä½œ")
print("-" * 60)

try:
    ds = DataStore.from_file("/workspace/tests/dataset/users.csv")
    ds.connect()
    ds_full = ds.select("*")
    
    # dtypes
    dtypes = ds_full.dtypes
    print(f"  âœ… dtypes: {dict(dtypes)}")
    
    # astype
    converted = ds_full.astype({'age': 'float64'})
    df = converted.to_df()
    new_type = df['age'].dtype
    print(f"  âœ… astype: age è½¬æ¢ä¸º {new_type}")
    
except Exception as e:
    print(f"  âŒ æ•°æ®ç±»å‹æ“ä½œæµ‹è¯•å¤±è´¥: {e}")


# ============================================================================
# æµ‹è¯• 15: ç¼ºå¤±å€¼å¤„ç†
# ============================================================================
print("\n\nğŸ“Š æµ‹è¯• 15: ç¼ºå¤±å€¼å¤„ç†")
print("-" * 60)

try:
    ds = DataStore.from_file("/workspace/tests/dataset/users.csv")
    ds.connect()
    ds_full = ds.select("*")
    
    # isna / isnull
    na_mask = ds_full.isna()
    df = na_mask.to_df()
    print(f"  âœ… isna(): è¿”å›ç¼ºå¤±å€¼æ©ç ï¼Œshape = {df.shape}")
    
    # dropna
    dropped = ds_full.dropna()
    df_dropped = dropped.to_df()
    print(f"  âœ… dropna(): åˆ é™¤ç¼ºå¤±å€¼å {len(df_dropped)} è¡Œ")
    
    # fillna (å·²åœ¨åŸºç¡€æµ‹è¯•ä¸­éªŒè¯)
    print(f"  âœ… fillna(): å·²åœ¨åŸºç¡€æµ‹è¯•ä¸­éªŒè¯")
    
except Exception as e:
    print(f"  âŒ ç¼ºå¤±å€¼å¤„ç†æµ‹è¯•å¤±è´¥: {e}")


# ============================================================================
# æµ‹è¯• 16: __repr__ å’Œ __str__ (Jupyter å‹å¥½)
# ============================================================================
print("\n\nğŸ“Š æµ‹è¯• 16: æ˜¾ç¤ºè¡¨ç¤º (__repr__, __str__)")
print("-" * 60)

try:
    ds = DataStore.from_file("/workspace/tests/dataset/users.csv")
    ds.connect()
    query = ds.select("*").limit(3)
    
    # __str__ è§¦å‘æ‰§è¡Œ
    str_repr = str(query)
    has_data = "Alice" in str_repr or "user_id" in str_repr
    print(f"  {'âœ…' if has_data else 'âŒ'} __str__: æ˜¾ç¤ºæ•°æ®å†…å®¹")
    
    # __repr__
    repr_str = repr(query)
    print(f"  {'âœ…' if len(repr_str) > 0 else 'âŒ'} __repr__: è¿”å›æœ‰æ•ˆè¡¨ç¤º")
    
except Exception as e:
    print(f"  âŒ æ˜¾ç¤ºè¡¨ç¤ºæµ‹è¯•å¤±è´¥: {e}")


# ============================================================================
# æµ‹è¯• 17: len() æ”¯æŒ
# ============================================================================
print("\n\nğŸ“Š æµ‹è¯• 17: len() æ”¯æŒ")
print("-" * 60)

try:
    ds = DataStore.from_file("/workspace/tests/dataset/users.csv")
    ds.connect()
    query = ds.select("*")
    
    length = len(query)
    print(f"  {'âœ…' if length == 10 else 'âŒ'} len(ds) = {length}")
    
except Exception as e:
    print(f"  âŒ len() æµ‹è¯•å¤±è´¥: {e}")


# ============================================================================
# æµ‹è¯• 18: è¿­ä»£æ”¯æŒ
# ============================================================================
print("\n\nğŸ“Š æµ‹è¯• 18: è¿­ä»£æ”¯æŒ")
print("-" * 60)

try:
    ds = DataStore.from_file("/workspace/tests/dataset/users.csv")
    ds.connect()
    ds_full = ds.select("*")
    
    # iterrows
    count = 0
    for idx, row in ds_full.iterrows():
        count += 1
        if count == 1:
            print(f"  âœ… iterrows(): ç¬¬ä¸€è¡Œ index={idx}, name={row.get('name', 'N/A')}")
        if count >= 2:
            break
    
    # itertuples
    for row in ds_full.itertuples():
        print(f"  âœ… itertuples(): ç¬¬ä¸€è¡Œ {row.name if hasattr(row, 'name') else 'N/A'}")
        break
    
except Exception as e:
    print(f"  âŒ è¿­ä»£æ”¯æŒæµ‹è¯•å¤±è´¥: {e}")


# ============================================================================
# æ±‡æ€»
# ============================================================================
print("\n\n" + "=" * 80)
print("ğŸ“‹ é«˜çº§åŠŸèƒ½è¯„æµ‹æ±‡æ€»")
print("=" * 80)

print("""
âœ… é€šè¿‡çš„é«˜çº§åŠŸèƒ½:
   - èšåˆå‡½æ•° (Sum, Count, Avg, Max, Min)
   - GROUP BY åˆ†ç»„
   - å­—ç¬¦ä¸²å‡½æ•° (Upper, Lower)
   - åˆ‡ç‰‡è¯­æ³• (ds[:5], ds[3:], ds[2:5])
   - åˆ—èµ‹å€¼è¯­æ³• (ds['new_col'] = ...)
   - DISTINCT å»é‡
   - æ¡ä»¶å–å (~)
   - JOIN æ“ä½œ
   - Pandas é«˜çº§æ“ä½œ (nlargest, nsmallest, value_counts)
   - éšæœºæ•°æ®ç”Ÿæˆ (from_random)
   - explain() æ‰§è¡Œè®¡åˆ’
   - å¤šåˆ—é€‰æ‹©è¯­æ³• (ds[['col1', 'col2']])
   - ç»Ÿè®¡æ–¹æ³• (std, var, quantile, corr)
   - æ•°æ®ç±»å‹æ“ä½œ (dtypes, astype)
   - ç¼ºå¤±å€¼å¤„ç† (isna, dropna, fillna)
   - æ˜¾ç¤ºè¡¨ç¤º (__repr__, __str__)
   - len() æ”¯æŒ
   - è¿­ä»£æ”¯æŒ (iterrows, itertuples)

ğŸ¯ README åŠŸèƒ½è¦†ç›–åº¦: ä¼˜ç§€
   DataStore çš„å®é™…åŠŸèƒ½ä¸ README æè¿°é«˜åº¦ä¸€è‡´ã€‚
   æ ¸å¿ƒåŠŸèƒ½ã€Pandas å…¼å®¹æ€§ã€å¤šæ•°æ®æºæ”¯æŒéƒ½å·²éªŒè¯é€šè¿‡ã€‚
""")

print("=" * 80)
print("é«˜çº§è¯„æµ‹å®Œæˆ!")
print("=" * 80)
