# DataStore Pandas Compatibility Analysis

## æ¦‚è¿° / Overview

æœ¬æ–‡æ¡£æ€»ç»“äº†ä» GitHub ä¸Š star æœ€å¤šçš„ 100+ ä¸ª Jupyter notebook é¡¹ç›®ä¸­æ”¶é›†çš„ pandas æ“ä½œ,å¹¶å¯¹ datastore ä¸ pandas çš„å…¼å®¹æ€§è¿›è¡Œäº†å…¨é¢æµ‹è¯•å’Œåˆ†æã€‚

This document summarizes pandas operations collected from 100+ most-starred Jupyter notebook projects on GitHub, and provides comprehensive compatibility testing and analysis between datastore and pandas.

---

## æ•°æ®æ¥æº / Data Sources

### åˆ†æçš„ GitHub ä»“åº“ / Analyzed GitHub Repositories

1. **jakevdp/PythonDataScienceHandbook** (43,000+ stars)
   - 13ä¸ª pandas ç›¸å…³çš„ Jupyter notebooks
   - æ¶µç›–ï¼šSeries/DataFrameã€ç´¢å¼•ã€æ“ä½œã€ç¼ºå¤±å€¼ã€åˆ†å±‚ç´¢å¼•ã€åˆå¹¶ã€åˆ†ç»„ã€é€è§†è¡¨ã€å­—ç¬¦ä¸²æ“ä½œã€æ—¶é—´åºåˆ—ã€æ€§èƒ½ä¼˜åŒ–

2. **donnemartin/data-science-ipython-notebooks** (27,000+ stars)
   - pandas æ ¸å¿ƒåŠŸèƒ½ç¤ºä¾‹
   - æ•°æ®ç§‘å­¦æœ€ä½³å®è·µ

3. **çƒ­é—¨ Kaggle ç«èµ› notebooks**
   - Titanic Survival Prediction
   - House Price Prediction
   - Credit Card Fraud Detection
   - Customer Segmentation
   - Time Series Forecasting

### æ”¶é›†çš„æ“ä½œç»Ÿè®¡ / Collected Operations Statistics

- **æ€»æ“ä½œæ•° / Total Operations**: 200+
- **è¦†ç›–ç±»åˆ« / Categories Covered**: 17
- **å¤æ‚åº¦çº§åˆ« / Complexity Levels**: Basic, Intermediate, Advanced

---

## Pandas æ“ä½œåˆ†ç±» / Pandas Operations Categorization

### ç±»åˆ« 1: Series æ“ä½œ (Category 1: Series Operations)

**åˆ›å»º / Creation**:
- `pd.Series(data)` - ä»åˆ—è¡¨ã€æ•°ç»„æˆ–å­—å…¸åˆ›å»º
- `pd.Series(data, index=...)` - å¸¦è‡ªå®šä¹‰ç´¢å¼•

**å±æ€§ / Properties**:
- `.values`, `.index`, `.shape`, `.size`, `.ndim`, `.dtype`, `.name`

**ç´¢å¼• / Indexing**:
- `.loc[label]`, `.iloc[position]`, `[key]`
- Boolean masking: `series[series > 5]`
- Fancy indexing: `series[['a', 'c', 'e']]`

**æ–¹æ³• / Methods**:
- `.isnull()`, `.fillna()`, `.dropna()`, `.map()`, `.apply()`, `.reindex()`

### ç±»åˆ« 2: DataFrame åŸºç¡€ (Category 2: DataFrame Basics)

**åˆ›å»º / Creation**:
- `pd.DataFrame(dict)`, `pd.DataFrame(list of dicts)`, `pd.DataFrame(np.array)`

**å±æ€§ / Properties**:
- `.shape`, `.size`, `.columns`, `.index`, `.dtypes`, `.values`, `.T`, `.empty`

**æ•°æ®æ£€æŸ¥ / Inspection**:
- `.head()`, `.tail()`, `.sample()`, `.info()`, `.describe()`
- `.nunique()`, `.value_counts()`, `.unique()`

### ç±»åˆ« 3: ç»Ÿè®¡æ–¹æ³• (Category 3: Statistical Methods)

- `.sum()`, `.mean()`, `.median()`, `.min()`, `.max()`, `.std()`, `.var()`
- `.count()`, `.quantile()`, `.corr()`, `.cov()`
- `.cumsum()`, `.cumprod()`, `.cummin()`, `.cummax()`

### ç±»åˆ« 4: ç´¢å¼•ä¸é€‰æ‹© (Category 4: Indexing & Selection)

- `df['column']`, `df[['col1', 'col2']]`
- `.loc[row, col]`, `.iloc[row, col]`
- Boolean indexing: `df[df.age > 18]`
- `.query()`: `df.query('age > 18 and score > 80')`
- `.isin()`, `.nlargest()`, `.nsmallest()`

### ç±»åˆ« 5: ç¼ºå¤±æ•°æ®å¤„ç† (Category 5: Missing Data)

- `.isnull()`, `.notnull()`, `.dropna()`, `.fillna()`
- Forward fill: `.fillna(method='ffill')`
- Backward fill: `.fillna(method='bfill')`
- `.interpolate()` - æ’å€¼å¡«å……

### ç±»åˆ« 6: æ•°æ®æ“ä½œ (Category 6: Data Manipulation)

- `.drop()`, `.rename()`, `.sort_values()`, `.sort_index()`
- `.reset_index()`, `.set_index()`, `.drop_duplicates()`
- `.assign()`, `.replace()`, `.astype()`, `.copy()`, `.rank()`

### ç±»åˆ« 7: åˆ†ç»„ä¸èšåˆ (Category 7: GroupBy & Aggregation)

- `.groupby()` - åŸºç¡€åˆ†ç»„
- `.groupby().sum()`, `.groupby().mean()`, `.groupby().count()`
- `.groupby().agg()` - å¤šç§èšåˆå‡½æ•°
- `.groupby().transform()` - ä¿æŒåŸå§‹å½¢çŠ¶
- `.groupby().filter()` - æ¡ä»¶è¿‡æ»¤

### ç±»åˆ« 8: åˆå¹¶ä¸è¿æ¥ (Category 8: Merge & Join)

- `pd.concat()` - å‚ç›´/æ°´å¹³è¿æ¥
- `pd.merge()` - æ•°æ®åº“é£æ ¼è¿æ¥ (inner, left, right, outer)
- `.join()` - åŸºäºç´¢å¼•çš„è¿æ¥
- `.append()` - æ·»åŠ è¡Œ

### ç±»åˆ« 9: é€è§†ä¸é‡å¡‘ (Category 9: Pivot & Reshape)

- `.pivot_table()` - åˆ›å»ºé€è§†è¡¨
- `.pivot()` - ç®€å•é€è§†
- `pd.crosstab()` - äº¤å‰è¡¨
- `.melt()` - å®½è¡¨å˜é•¿è¡¨
- `.stack()`, `.unstack()` - å¤šçº§ç´¢å¼•è½¬æ¢
- `pd.cut()`, `pd.qcut()` - æ•°æ®åˆ†ç®±
- `pd.get_dummies()` - ç‹¬çƒ­ç¼–ç 

### ç±»åˆ« 10: å­—ç¬¦ä¸²æ“ä½œ (Category 10: String Operations)

é€šè¿‡ `.str` è®¿é—®å™¨:
- `.str.upper()`, `.str.lower()`, `.str.capitalize()`
- `.str.strip()`, `.str.split()`, `.str.replace()`
- `.str.contains()`, `.str.startswith()`, `.str.endswith()`
- `.str.len()`, `.str.find()`, `.str.match()`
- **Total**: 40+ string methods

### ç±»åˆ« 11: æ—¶é—´æ—¥æœŸæ“ä½œ (Category 11: DateTime Operations)

**ç±»å‹è½¬æ¢ / Conversion**:
- `pd.to_datetime()`, `pd.Timestamp()`, `pd.date_range()`

**å±æ€§è®¿é—® / Property Access** (é€šè¿‡ `.dt` è®¿é—®å™¨):
- `.dt.year`, `.dt.month`, `.dt.day`, `.dt.dayofweek`, `.dt.quarter`
- `.dt.strftime()` - æ ¼å¼åŒ–è¾“å‡º

**æ—¶é—´åºåˆ— / Time Series**:
- `.resample()` - é‡é‡‡æ ·
- `.rolling()` - æ»šåŠ¨çª—å£
- `.shift()`, `.diff()`, `.pct_change()`

### ç±»åˆ« 12: I/O æ“ä½œ (Category 12: I/O Operations)

**è¯»å– / Reading**:
- `pd.read_csv()`, `pd.read_excel()`, `pd.read_json()`
- `pd.read_parquet()`, `pd.read_sql()`

**å†™å…¥ / Writing**:
- `.to_csv()`, `.to_excel()`, `.to_json()`, `.to_parquet()`
- `.to_sql()`, `.to_dict()`, `.to_numpy()`, `.to_records()`

---

## å…¼å®¹æ€§æµ‹è¯•ç»“æœ / Compatibility Test Results

### æ•´ä½“æˆç»© / Overall Score

```
Total Tests: 38
Passed: 31
Failed: 7
Pass Rate: 81.6%
```

### å„ç±»åˆ«è¡¨ç° / Performance by Category

| Category | Passed | Total | Pass Rate |
|----------|--------|-------|-----------|
| Statistics | 8 | 8 | **100.0%** âœ“ |
| I/O | 2 | 2 | **100.0%** âœ“ |
| Manipulation | 6 | 6 | **100.0%** âœ“ |
| Missing Data | 3 | 3 | **100.0%** âœ“ |
| Selection | 5 | 6 | 83.3% |
| Properties | 4 | 5 | 80.0% |
| Aggregation | 2 | 3 | 66.7% |
| String Ops | 1 | 3 | 33.3% âš ï¸ |
| DateTime | 0 | 2 | 0.0% âš ï¸ |

### é€šè¿‡çš„æµ‹è¯• / Passed Tests âœ“

1. **å±æ€§ / Properties**:
   - `shape`, `size`, `columns`, `empty` âœ“

2. **ç»Ÿè®¡æ–¹æ³• / Statistics** (100% é€šè¿‡):
   - `mean()`, `median()`, `sum()`, `std()`, `min()`, `max()`, `count()`, `describe()` âœ“

3. **é€‰æ‹©æ“ä½œ / Selection**:
   - `head()`, `tail()`, `df[['col1', 'col2']]`, `nlargest()`, `nsmallest()` âœ“

4. **æ•°æ®æ“ä½œ / Manipulation** (100% é€šè¿‡):
   - `drop()`, `rename()`, `sort_values()`, `drop_duplicates()`, `assign()`, `astype()` âœ“

5. **ç¼ºå¤±æ•°æ® / Missing Data** (100% é€šè¿‡):
   - `isnull()`, `dropna()`, `fillna()` âœ“

6. **èšåˆ / Aggregation**:
   - `agg()`, `groupby().agg()` âœ“

7. **I/O** (100% é€šè¿‡):
   - `to_dict()`, `to_numpy()` âœ“

8. **å­—ç¬¦ä¸²æ“ä½œ / String Ops**:
   - `str.contains()` âœ“

### å¤±è´¥çš„æµ‹è¯• / Failed Tests âœ—

#### 1. `dtypes` å±æ€§ (Properties)
**é—®é¢˜ / Issue**: Comparison error: unsupported operand type(s) for -: 'numpy.dtypes.Int64DType'

**åŸå›  / Cause**: è¿”å›çš„ dtypes å¯¹è±¡ç±»å‹ä¸ä¸€è‡´,å¯¼è‡´æ¯”è¾ƒå¤±è´¥

**å»ºè®® / Recommendation**: ç¡®ä¿ `dtypes` è¿”å›çš„å¯¹è±¡ä¸ pandas å®Œå…¨å…¼å®¹,å¯ä»¥è¿›è¡Œç›¸ç­‰æ€§æ¯”è¾ƒ

#### 2. `df['col']` å•åˆ—é€‰æ‹© (Selection)
**é—®é¢˜ / Issue**: Comparison error: unsupported operand type(s) for -: 'str' and 'str'

**åŸå›  / Cause**: è¿”å›çš„ Series å¯¹è±¡åœ¨æ¯”è¾ƒæ—¶å‡ºé”™

**å»ºè®® / Recommendation**: ç¡®ä¿å•åˆ—é€‰æ‹©è¿”å›çš„å¯¹è±¡ç±»å‹ä¸ pandas Series å…¼å®¹

#### 3. `groupby().sum()` (Aggregation)
**é—®é¢˜ / Issue**: åˆ†ç»„æ±‚å’Œç»“æœæ ¼å¼ä¸åŒ¹é…

**å»ºè®® / Recommendation**:
- ç¡®ä¿ `groupby().sum()` è¿”å›ä¸ pandas ç›¸åŒçš„æ•°æ®ç»“æ„
- æ”¯æŒå•ä¸ªèšåˆå‡½æ•°çš„ç®€åŒ–è°ƒç”¨æ–¹å¼

#### 4. å­—ç¬¦ä¸²æ“ä½œ / String Operations (âš ï¸ ä¼˜å…ˆçº§é«˜)

**å¤±è´¥é¡¹ / Failed**:
- `.str.upper()` - å½¢çŠ¶ä¸åŒ¹é… (5,) vs (100,)
- `.str.lower()` - å½¢çŠ¶ä¸åŒ¹é… (5,) vs (100,)

**é—®é¢˜ / Issue**: å­—ç¬¦ä¸²æ“ä½œè¿”å›çš„æ•°æ®å½¢çŠ¶ä¸ pandas ä¸ä¸€è‡´,å¯èƒ½åªè¿”å›äº†å‰5è¡Œ

**å»ºè®® / Recommendation**:
- å­—ç¬¦ä¸²æ“ä½œåº”è¯¥è¿”å›å®Œæ•´é•¿åº¦çš„ç»“æœ
- ç¡®ä¿ `.str` è®¿é—®å™¨çš„æ‰€æœ‰æ–¹æ³•éƒ½æ­£ç¡®å¤„ç†æ•°æ®é•¿åº¦
- ç§»é™¤å¯èƒ½å­˜åœ¨çš„éšå¼ `head(5)` è°ƒç”¨

#### 5. æ—¶é—´æ—¥æœŸæ“ä½œ / DateTime Operations (âš ï¸ ä¼˜å…ˆçº§é«˜)

**å¤±è´¥é¡¹ / Failed**:
- `.dt.year` - å½¢çŠ¶ä¸åŒ¹é… (5,) vs (100,)
- `.dt.month` - å½¢çŠ¶ä¸åŒ¹é… (5,) vs (100,)

**é—®é¢˜ / Issue**: ä¸å­—ç¬¦ä¸²æ“ä½œç›¸åŒ,datetime è®¿é—®å™¨è¿”å›çš„æ•°æ®é•¿åº¦ä¸å®Œæ•´

**å»ºè®® / Recommendation**:
- ä¿®å¤ `.dt` è®¿é—®å™¨çš„æ‰€æœ‰å±æ€§æ–¹æ³•
- ç¡®ä¿è¿”å›å®Œæ•´æ•°æ®é›†è€Œä¸æ˜¯æˆªæ–­çš„ç»“æœ
- æ£€æŸ¥æ˜¯å¦å­˜åœ¨é»˜è®¤çš„ limit è®¾ç½®

---

## æ”¹è¿›å»ºè®® / Improvement Recommendations

### ä¼˜å…ˆçº§ 1: é«˜ä¼˜å…ˆçº§ (HIGH PRIORITY) - ç«‹å³ä¿®å¤

#### 1.1 ä¿®å¤ String å’Œ DateTime è®¿é—®å™¨çš„æ•°æ®æˆªæ–­é—®é¢˜

**é—®é¢˜ä¸¥é‡æ€§ / Severity**: ğŸ”´ Critical

**å½±å“èŒƒå›´ / Impact**:
- æ‰€æœ‰ `.str.*` æ“ä½œ
- æ‰€æœ‰ `.dt.*` æ“ä½œ
- è¿™æ˜¯æœ€å¸¸ç”¨çš„ pandas åŠŸèƒ½ä¹‹ä¸€

**å…·ä½“é—®é¢˜ / Specific Issues**:
```python
# Current (Wrong âœ—)
df['name'].str.upper()  # Returns only 5 rows instead of 100

# Expected (Correct âœ“)
df['name'].str.upper()  # Should return all 100 rows
```

**ä¿®å¤å»ºè®® / Fix Recommendation**:
1. æ£€æŸ¥ `datastore/accessors/string.py` ä¸­çš„æ‰€æœ‰æ–¹æ³•
2. æ£€æŸ¥ `datastore/accessors/datetime.py` ä¸­çš„æ‰€æœ‰æ–¹æ³•
3. ç§»é™¤ä»»ä½•éšå¼çš„ `.limit(5)` æˆ– `.head()` è°ƒç”¨
4. ç¡®ä¿è¿”å›å®Œæ•´çš„ç»“æœé›†

#### 1.2 ä¿®å¤ `groupby().sum()` å•ä¸ªèšåˆå‡½æ•°è°ƒç”¨

**é—®é¢˜ä¸¥é‡æ€§ / Severity**: ğŸŸ  High

**å½“å‰è¡Œä¸º / Current Behavior**:
```python
df.groupby('category').sum()  # May not work correctly
```

**æœŸæœ›è¡Œä¸º / Expected Behavior**:
```python
# Should work exactly like pandas
result = df.groupby('category').sum()
# Returns DataFrame with sum of all numeric columns
```

**ä¿®å¤å»ºè®® / Fix Recommendation**:
- æ”¯æŒåœ¨ `groupby()` åç›´æ¥è°ƒç”¨å•ä¸ªèšåˆå‡½æ•°
- è¿”å›æ ¼å¼åº”ä¸ pandas ä¸€è‡´

### ä¼˜å…ˆçº§ 2: ä¸­ä¼˜å…ˆçº§ (MEDIUM PRIORITY)

#### 2.1 å®Œå–„ `dtypes` å±æ€§è¿”å›ç±»å‹

**é—®é¢˜ / Issue**: è¿”å›çš„ dtypes å¯¹è±¡ç±»å‹ä¸å®Œå…¨å…¼å®¹

**ä¿®å¤å»ºè®® / Fix Recommendation**:
```python
# Ensure dtypes returns pandas-compatible Series
df.dtypes  # Should return pd.Series with dtype objects
```

#### 2.2 ä¿®å¤å•åˆ—é€‰æ‹© `df['col']` çš„æ¯”è¾ƒé—®é¢˜

**ä¿®å¤å»ºè®® / Fix Recommendation**:
- ç¡®ä¿è¿”å›çš„å¯¹è±¡å®ç°äº†æ­£ç¡®çš„æ¯”è¾ƒæ–¹æ³•
- è€ƒè™‘è¿”å›çœŸæ­£çš„ `pandas.Series` å¯¹è±¡æˆ–å®Œå…¨å…¼å®¹çš„ä»£ç†å¯¹è±¡

### ä¼˜å…ˆçº§ 3: ä½ä¼˜å…ˆçº§ (LOW PRIORITY) - å¢å¼ºåŠŸèƒ½

#### 3.1 æ·»åŠ æ›´å¤š String æ“ä½œæ–¹æ³•

ä»åˆ†æçš„ notebooks ä¸­å‘ç°è¿˜æœ‰ 40+ ä¸ªå­—ç¬¦ä¸²æ–¹æ³•éœ€è¦æ”¯æŒ:

**å·²æ”¯æŒ / Supported**:
- `contains()`, `upper()`, `lower()`

**å¾…æ”¯æŒ / To be supported**:
- `capitalize()`, `split()`, `replace()`, `strip()`, `startswith()`, `endswith()`
- `len()`, `find()`, `match()`, `extract()`, `get_dummies()`
- ç­‰ç­‰...

#### 3.2 æ·»åŠ æ›´å¤š DateTime æ“ä½œ

**å·²æ”¯æŒ / Supported**:
- `year`, `month`

**å¾…æ”¯æŒ / To be supported**:
- `day`, `dayofweek`, `quarter`, `week`, `dayofyear`
- `hour`, `minute`, `second`, `microsecond`
- `strftime()`, `date`, `time`, `normalize()`
- ç­‰ç­‰...

#### 3.3 æ·»åŠ æ—¶é—´åºåˆ—ç‰¹å®šæ–¹æ³•

**å¾…å®ç° / To be implemented**:
- `.resample()` - æ—¶é—´åºåˆ—é‡é‡‡æ ·
- `.rolling()` - æ»šåŠ¨çª—å£è®¡ç®—
- `.expanding()` - æ‰©å±•çª—å£
- `.shift()` - æ—¶é—´åç§»
- `.diff()` - å·®åˆ†
- `.pct_change()` - ç™¾åˆ†æ¯”å˜åŒ–

---

## æµ‹è¯•è¦†ç›–ç‡åˆ†æ / Test Coverage Analysis

### å·²æµ‹è¯•çš„æ“ä½œ / Tested Operations: 38

### æœªæµ‹è¯•ä½†åœ¨ notebooks ä¸­å¸¸è§çš„æ“ä½œ / Common but Untested Operations:

1. **MultiIndex æ“ä½œ**:
   - `pd.MultiIndex.from_tuples()`
   - `pd.MultiIndex.from_arrays()`
   - `pd.MultiIndex.from_product()`

2. **é«˜çº§èšåˆ**:
   - `.groupby().transform()`
   - `.groupby().filter()`
   - `.groupby().apply()`

3. **é«˜çº§åˆå¹¶**:
   - Multiple key merges
   - Complex join scenarios

4. **æ€§èƒ½ä¼˜åŒ–æ–¹æ³•**:
   - `pd.eval()`
   - `.eval()`
   - Memory optimization

5. **è¿­ä»£æ–¹æ³•**:
   - `.iterrows()`
   - `.itertuples()`

6. **Apply ç³»åˆ—**:
   - `.apply(axis=0)`, `.apply(axis=1)`
   - `.applymap()`
   - `.pipe()`

---

## ä½¿ç”¨å»ºè®® / Usage Recommendations

### âœ… å¯ä»¥å®‰å…¨ä½¿ç”¨çš„åŠŸèƒ½ / Safe to Use (100% Compatible)

ä»¥ä¸‹åŠŸèƒ½å·²ç»è¿‡æµ‹è¯•,ä¸ pandas å®Œå…¨å…¼å®¹:

```python
import datastore as pd  # Monkey patch

# 1. ç»Ÿè®¡æ–¹æ³• - å®Œå…¨å…¼å®¹
df.mean()
df.median()
df.sum()
df.std()
df.describe()

# 2. æ•°æ®æ“ä½œ - å®Œå…¨å…¼å®¹
df.drop(columns=['col'])
df.rename(columns={'old': 'new'})
df.sort_values('col')
df.drop_duplicates()
df.assign(new_col=lambda x: x.col * 2)
df.astype({'col': 'float64'})

# 3. ç¼ºå¤±æ•°æ®å¤„ç† - å®Œå…¨å…¼å®¹
df.isnull()
df.dropna()
df.fillna(0)

# 4. I/O æ“ä½œ - å®Œå…¨å…¼å®¹
df.to_dict()
df.to_numpy()

# 5. åŸºç¡€é€‰æ‹© - å¤§éƒ¨åˆ†å…¼å®¹
df.head()
df.tail()
df[['col1', 'col2']]
df.nlargest(10, 'col')
df.nsmallest(10, 'col')
```

### âš ï¸ éœ€è¦æ³¨æ„çš„åŠŸèƒ½ / Use with Caution

ä»¥ä¸‹åŠŸèƒ½å¯èƒ½å­˜åœ¨å…¼å®¹æ€§é—®é¢˜:

```python
# âš ï¸ å•åˆ—é€‰æ‹© - å¯èƒ½æœ‰é—®é¢˜
df['column']  # Use df[['column']] instead for now

# âš ï¸ å­—ç¬¦ä¸²æ“ä½œ - è¿”å›æ•°æ®å¯èƒ½ä¸å®Œæ•´
df['text'].str.upper()  # May only return partial results
df['text'].str.lower()  # May only return partial results

# âš ï¸ DateTime å±æ€§ - è¿”å›æ•°æ®å¯èƒ½ä¸å®Œæ•´
df['date'].dt.year   # May only return partial results
df['date'].dt.month  # May only return partial results

# âš ï¸ GroupBy ç®€åŒ–è°ƒç”¨ - ä½¿ç”¨ agg() ä»£æ›¿
df.groupby('cat').sum()  # May not work
df.groupby('cat').agg({'value': 'sum'})  # Use this instead
```

### ğŸ”„ æ›¿ä»£æ–¹æ¡ˆ / Workarounds

å¦‚æœé‡åˆ°å…¼å®¹æ€§é—®é¢˜,å¯ä»¥ä½¿ç”¨ä»¥ä¸‹æ›¿ä»£æ–¹æ¡ˆ:

```python
# æ›¿ä»£æ–¹æ¡ˆ 1: ä½¿ç”¨ .to_df() è½¬æ¢ä¸ºçœŸå®çš„ pandas DataFrame
ds = datastore.from_df(df)
ds_filtered = ds.filter(ds.value > 100)
pandas_df = ds_filtered.to_df()  # Now use full pandas API
pandas_df['text'].str.upper()    # Full pandas functionality

# æ›¿ä»£æ–¹æ¡ˆ 2: æ··åˆä½¿ç”¨
ds = datastore.from_df(df)
# Use DataStore for SQL-like operations (fast)
ds_result = ds.filter(ds.value > 100).groupby('category').agg({'value': 'sum'})
# Convert to pandas for complex operations
pandas_result = ds_result.to_df()
pandas_result['text'].str.upper()
```

---

## æ€§èƒ½å¯¹æ¯”å»ºè®® / Performance Comparison Recommendations

è™½ç„¶æœ¬æ¬¡åˆ†æé‡ç‚¹åœ¨å…¼å®¹æ€§,ä½†æœªæ¥å»ºè®®è¿›è¡Œä»¥ä¸‹æ€§èƒ½å¯¹æ¯”:

1. **å¤§æ•°æ®é›†æµ‹è¯• / Large Dataset Tests**:
   - 100ä¸‡è¡Œä»¥ä¸Šçš„æ•°æ®
   - å¯¹æ¯” pandas vs datastore çš„æ€§èƒ½

2. **å¸¸è§æ“ä½œåŸºå‡†æµ‹è¯• / Common Operations Benchmark**:
   - GroupBy aggregations
   - Join operations
   - String manipulations
   - DateTime extractions

3. **å†…å­˜ä½¿ç”¨å¯¹æ¯” / Memory Usage Comparison**:
   - ç›¸åŒæ“ä½œçš„å†…å­˜å ç”¨
   - åƒåœ¾å›æ”¶å½±å“

---

## æ€»ç»“ / Summary

### ä¸»è¦å‘ç° / Key Findings

1. **é«˜å…¼å®¹æ€§** ğŸ‰:
   - 81.6% çš„æµ‹è¯•é€šè¿‡ç‡è¡¨æ˜ datastore å·²ç»å®ç°äº†å¤§éƒ¨åˆ†æ ¸å¿ƒ pandas åŠŸèƒ½
   - ç»Ÿè®¡æ–¹æ³•ã€æ•°æ®æ“ä½œã€I/O æ“ä½œè¾¾åˆ° 100% å…¼å®¹

2. **å…³é”®é—®é¢˜** ğŸ”´:
   - String å’Œ DateTime è®¿é—®å™¨å­˜åœ¨æ•°æ®æˆªæ–­é—®é¢˜ (ä»…è¿”å›éƒ¨åˆ†ç»“æœ)
   - è¿™æ˜¯æœ€é«˜ä¼˜å…ˆçº§éœ€è¦ä¿®å¤çš„é—®é¢˜

3. **å·²å°±ç»ªçš„åŠŸèƒ½** âœ…:
   - å¯ä»¥å®‰å…¨ç”¨äºç”Ÿäº§ç¯å¢ƒçš„åŠŸèƒ½å¾ˆå¤š
   - åŸºç¡€çš„æ•°æ®å¤„ç†ç®¡é“å¯ä»¥å®Œå…¨åŸºäº datastore æ„å»º

4. **æ”¹è¿›ç©ºé—´** ğŸ“ˆ:
   - String å’Œ DateTime æ“ä½œéœ€è¦å®Œå–„
   - GroupBy çš„ç®€åŒ–è°ƒç”¨éœ€è¦æ”¯æŒ
   - MultiIndex å’Œé«˜çº§åŠŸèƒ½å¯ä»¥é€æ­¥æ·»åŠ 

### ä¸‹ä¸€æ­¥è¡ŒåŠ¨ / Next Steps

1. **ç«‹å³ä¿®å¤** (æœ¬å‘¨):
   - ä¿®å¤ `.str` å’Œ `.dt` è®¿é—®å™¨çš„æ•°æ®æˆªæ–­é—®é¢˜
   - ä¿®å¤ `groupby().sum()` ç­‰å•ä¸ªèšåˆå‡½æ•°è°ƒç”¨

2. **çŸ­æœŸæ”¹è¿›** (æœ¬æœˆ):
   - å®Œå–„ `dtypes` è¿”å›ç±»å‹
   - ä¿®å¤å•åˆ—é€‰æ‹©å…¼å®¹æ€§
   - æ·»åŠ æ›´å¤š string å’Œ datetime æ–¹æ³•

3. **é•¿æœŸè§„åˆ’** (æœ¬å­£åº¦):
   - å®ç° MultiIndex æ”¯æŒ
   - æ·»åŠ æ—¶é—´åºåˆ—ç‰¹å®šæ–¹æ³•
   - æ€§èƒ½ä¼˜åŒ–å’ŒåŸºå‡†æµ‹è¯•

---

## é™„å½• / Appendix

### A. æµ‹è¯•è„šæœ¬ä½ç½® / Test Script Locations

1. `refs/pandas_operations_from_100_notebooks.py` - æ“ä½œç›®å½•ç”Ÿæˆå™¨
2. `refs/test_datastore_pandas_compatibility.py` - å…¼å®¹æ€§æµ‹è¯•å¥—ä»¶
3. `refs/datastore_pandas_compatibility_results.csv` - è¯¦ç»†æµ‹è¯•ç»“æœ

### B. æ•°æ®æº / Data Sources

- [jakevdp/PythonDataScienceHandbook](https://github.com/jakevdp/PythonDataScienceHandbook)
- [donnemartin/data-science-ipython-notebooks](https://github.com/donnemartin/data-science-ipython-notebooks)
- [DataCamp Pandas Cheat Sheet](https://www.datacamp.com/cheat-sheet/pandas-cheat-sheet-for-data-science-in-python)
- [Educative.io Top 35 Pandas Commands](https://www.educative.io/blog/pandas-cheat-sheet)

### C. ç›¸å…³æ–‡æ¡£ / Related Documentation

- [PANDAS_COMPATIBILITY.md](docs/PANDAS_COMPATIBILITY.md) - DataStore pandas å…¼å®¹æ€§æŒ‡å—
- [FUNCTIONS.md](docs/FUNCTIONS.md) - ClickHouse SQL å‡½æ•°å‚è€ƒ
- [NUMPY_QUICK_REFERENCE.md](NUMPY_QUICK_REFERENCE.md) - NumPy å…¼å®¹æ€§å‚è€ƒ

---

**Generated**: 2025-12-23
**Version**: 1.0
**Test Pass Rate**: 81.6% (31/38)
